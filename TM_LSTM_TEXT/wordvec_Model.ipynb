{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import _pickle as cPickle\n",
    "import random, re, os, collections\n",
    "import Config\n",
    "import csv\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from gensim.models import FastText\n",
    "config = Config.Config()\n",
    "config.vocab_size += 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Read_Train_Data(config):\n",
    "\n",
    "    with open(os.path.join(config.data_dir, 'train_dataset.csv'), 'r', encoding='utf8', errors='ignore') as ftext:\n",
    "        reader = pd.read_csv(ftext)\n",
    "    # Cleaning the texts\n",
    "        trainingdata = []\n",
    "        doc = []\n",
    "        keywords = []\n",
    "        for i in range(0, reader.shape[0]):\n",
    "            review = re.sub('[^a-zA-Z]', ' ', reader['Description'][i])\n",
    "            review = review.lower()\n",
    "\n",
    "            review = review.split()\n",
    "            #review = [' '.join(review)]\n",
    "            doc.append(review)\n",
    "        \n",
    "        #for i in range(0, reader.shape[0]):\n",
    "            reviewq = re.sub('[^a-zA-Z]', ' ', reader['Product_name'][i])\n",
    "            reviewq = reviewq.lower()\n",
    "\n",
    "            reviewq = reviewq.split()\n",
    "            #review = ' '.join(review)\n",
    "            keywords.append(reviewq)\n",
    "            \n",
    "        trainingdata = doc + keywords    \n",
    "    return trainingdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Read_Train_Data(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create CBOW model\n",
    "model1 = Word2Vec(data, size=200, window=5, min_count=3, workers=4)\n",
    "model1.train(data, total_examples=len(data), epochs=10)\n",
    "model1.wv.save_word2vec_format('Data/vec_1')\n",
    "#model1.wv.save_word2vec_format(config.data_dir+\"vec_1.txt\", binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create CBOW model\n",
    "model1 = Word2Vec(data, size=5, window=5, min_count=3, workers=4)\n",
    "model1.train(data, total_examples=len(data), epochs=10)\n",
    "model1.wv.save_word2vec_format('Data/vec_2')\n",
    "#model1.wv.save_word2vec_format(config.data_dir+\"vec_1.txt\", binary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Skip Gram model\n",
    "model3 = Word2Vec(data, min_count=3, size=5, window=5,workers=4, sg = 1)\n",
    "model3.train(data, total_examples=len(data), epochs=10)\n",
    "model3.wv.save_word2vec_format('Data/vec_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
